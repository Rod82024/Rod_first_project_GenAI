{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project to confirm saved model properly provides the expected output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6280d99-4322-43be-b10a-6761e2e97a51",
   "metadata": {},
   "source": [
    "#### Student: Rodrigo Quezada Reyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad2f77-ef7c-496f-865e-3491222b02ed",
   "metadata": {},
   "source": [
    "#### The Udacity platform was having Connection Failed over and over again during training or evaluation so rather perform locally with my GPU and will submit as a zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5050f-c7f5-4896-8c5f-65b20e657af0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "Describing my choices for each of the following:\n",
    "\n",
    "* PEFT technique: Lora as I find it a great option for fine-tuning while freezing a lot of paremeters for computation effiency.\n",
    "* Model: deberta-v2-xlarge because it is a great model for text classification tasks and this is one of those.\n",
    "* Evaluation approach: Performing initial evaluation with the foundational model, then performing the same evaluation using the trained Peft Model. This will allow a fair comparison of the model as is compared to the model fine-tuned.\n",
    "* Fine-tuning dataset: Hugging Face tweet_eval dataset as it is an interesting collection of tweet-based benchmark tasks designed for evaluating text classification models on social media content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "* I am selecting to load as my chosen pre-trained foundational model, the deberta-v2-xlarge after assessing its capability for classification tasks.\n",
    "* I will evaluate its performance prior to fine-tuning and then after fine-tuning. \n",
    "* I will also include loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d21f21",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e94f0",
   "metadata": {},
   "source": [
    "#### Import all dependencies including the Hugging Face PEFT Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335bc74f-d9a3-45c6-9fe3-f81c7f80a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccc73b0-8dc6-4733-9ab6-e319da8ea71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b96d81-b39e-4b37-a763-44a19db347b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb3a30-517b-4ca9-ae67-ba567608d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7ed12f-b484-44d2-8205-aa6bd78b8c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n",
      "12.6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Importing the torch library\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eda7c52-2a33-4322-85db-4766da363758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "889ac152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the rest of the libraries\n",
    "\n",
    "from peft import LoraConfig\n",
    "from peft import TaskType\n",
    "from transformers import AutoModelForCausalLM,AutoModelForSequenceClassification\n",
    "from peft import get_peft_model\n",
    "from peft import AutoPeftModelForCausalLM,AutoPeftModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from transformers import pipeline, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from transformers import DebertaV2ForSequenceClassification, DebertaV2Tokenizer\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "import sentencepiece\n",
    "#import protobuf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d87fa2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "# Verify if GPU is available\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19dda902-ae79-40c7-ab41-39a3b16bed27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finetuned_814_2347_model', 'finetuned_814_model', 'finetuned_816_model', 'original_lora_peft_8142133_model', 'patent_class']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./tmp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcde949e-9526-42d8-98f9-7a04e1a332ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['finetuned_8162335_model_v1', 'finetuned_8282025_model_v2', 'finetuned_8282025_model_v3', 'finetuned_8282025_model_v4', 'finetuned_8282025_model_v5', 'initial_lora_model_8282025_v0', 'initial_lora_model_8282025_v01']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./saved_models\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd491875-6316-4208-b434-1a7d802c60cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "#print(os.path.exists(\"./tmp/mod2347_model\"))\n",
    "#print(os.listdir(\"./tmp/mod2347_model\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79b3e0f-8af2-42f1-9ea4-0f77fc745822",
   "metadata": {},
   "source": [
    "### Reviewer request\n",
    "\n",
    "•\tYou must use the AUTO PEFT Model Hugging Face class: AutoPeftModelForSequenceClassification\n",
    "•\tThis ensures you're leveraging the Parameter-Efficient Fine-Tuning (PEFT) capabilities designed for models like LoRA, Prefix Tuning, and more — making your model both efficient and scalable.\n",
    "\n",
    "loaded_peft_model = AutoPeftModelForSequenceClassification.from_pretrained(\"/tmp/peft_model\", num_labels=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccaf9360-5ef8-4401-b491-7dacee5c3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\dslab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\safetensors\\torch.py:315: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  result[k] = f.get_tensor(k)\n"
     ]
    }
   ],
   "source": [
    "load_dir = \"./saved_models/finetuned_8282025_model_v4\"\n",
    "\n",
    "#my_816_model = AutoPeftModelForSequenceClassification.from_pretrained(load_dir)\n",
    "\n",
    "loaded_peft_model = AutoPeftModelForSequenceClassification.from_pretrained(load_dir, num_labels=4)\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(load_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7db930b-6b46-43c5-a280-d3be2f5c0160",
   "metadata": {},
   "source": [
    "Since the loading above, the classification head gets randomly reinitialized so the trained parameters are getting lost.\n",
    "\n",
    "Thus, need to save the trained model with Classification head weights saved too. \n",
    "\n",
    "Thus creating a new saved version as model V5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74a1dedf-e72f-45cb-95e5-bc1a489b644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "load_dir = \"./saved_models/finetuned_8282025_model_v5\"\n",
    "\n",
    "loaded_peft_model = AutoPeftModelForSequenceClassification.from_pretrained(\n",
    "    load_dir, \n",
    "    num_labels=4\n",
    ")\n",
    "\n",
    "# Load the full state including classification head\n",
    "state_dict = torch.load(f\"{load_dir}/full_model_state.bin\")\n",
    "loaded_peft_model.load_state_dict(state_dict)\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(load_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5190d40-5b4d-492b-9a24-bdd3b28c4f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nI recall using the original one created issues with the last layer but will try\\n\\nload_dir = \"./saved_models/finetuned_8162335_model_v1\"\\n\\nmy_816_model = AutoModelForSequenceClassification.from_pretrained(load_dir)\\nnew_tokenizer = AutoTokenizer.from_pretrained(load_dir)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "I recall using the original one created issues with the last layer but will try\n",
    "\n",
    "load_dir = \"./saved_models/finetuned_8162335_model_v1\"\n",
    "\n",
    "my_816_model = AutoModelForSequenceClassification.from_pretrained(load_dir)\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(load_dir)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c76b0ab-d6b4-44c2-8b81-5c4c088c97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 4\n",
      "Vocab size: 128000\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "#print(my_816_model.config.num_labels)   # should show 4, not 2\n",
    "#print(new_tokenizer.get_vocab_size()) ... this gets an error since Hugging Face’s DebertaV2TokenizerFast doesn’t expose get_vocab_size() (some tokenizers do, some don’t).\n",
    "\n",
    "#print(\"Number of labels:\", my_816_model.config.num_labels)  # should be 4\n",
    "print(\"Number of labels:\", loaded_peft_model.config.num_labels)  # should be 4\n",
    "print(\"Vocab size:\", new_tokenizer.vocab_size)           # or len(tokenizer.get_vocab())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e0ed706-60e3-4e74-8c12-b4d4165748dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval of the saved merged and fine-tuned model object\n",
    "\n",
    "#ft_lora_model = AutoPeftModelForCausalLM.from_pretrained(\"./tmp/finetuned_814_2347_model\")\n",
    "\n",
    "#from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#model_path = r\"C:\\Users\\dslab\\Downloads\\tmp\\patent_class\\checkpoint-6514\"\n",
    "\n",
    "#ft_lora_model = AutoModelForSequenceClassification.from_pretrained(\n",
    " #   model_path,\n",
    "  #  num_labels=4,\n",
    "   # local_files_only=True,\n",
    "    #ignore_mismatched_sizes=True\n",
    "#)\n",
    "\n",
    "#ft_lora_model = DebertaV2ForSequenceClassification.from_pretrained(model_path, local_files_only=True)\n",
    "#ft_tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "\n",
    "#ft_lora_model = DebertaV2ForSequenceClassification.from_pretrained(\".tmp/patent_class/checkpoint-651/finetuned_814_2347_model\", local_files_only=True)\n",
    "#ft_lora_model = DebertaV2ForSequenceClassification.from_pretrained(\"./tmp/mod2347_model\", local_files_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "576c2c7b-f379-4863-99ee-0fd6bae2b4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\nprint(os.path.exists(\"./tmp/finetuned_mod2347_model\"))\\nprint(os.listdir(\"./tmp/finetuned_mod2347_model\"))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "print(os.path.exists(\"./tmp/finetuned_mod2347_model\"))\n",
    "print(os.listdir(\"./tmp/finetuned_mod2347_model\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94f3cdd0-686c-4fb9-9401-93527d00415c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nfor root, dirs, files in os.walk(\"./tmp\"):\\n    if \"config.json\" in files:\\n        print(root)\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "for root, dirs, files in os.walk(\"./tmp\"):\n",
    "    if \"config.json\" in files:\n",
    "        print(root)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "495920da-6c2d-4eb3-a7e8-9ba57b8db873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor root, dirs, files in os.walk(\".\"):\\n    if \"config.json\" in files:\\n        print(root)\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for root, dirs, files in os.walk(\".\"):\n",
    "    if \"config.json\" in files:\n",
    "        print(root)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187f77d1-b53b-47e7-a2f8-c6da84d72531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\nprint(os.path.exists(\"./tmp/finetuned_814_2347_model\"))\\nprint(os.listdir(\"./tmp/finetuned_814_2347_model\"))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "print(os.path.exists(\"./tmp/finetuned_814_2347_model\"))\n",
    "print(os.listdir(\"./tmp/finetuned_814_2347_model\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0071154-d71f-4181-b23d-eadad6f9b617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport json\\n#with open(\"./tmp/finetuned_mod2347_model/config.json\") as f:\\nwith open(\"./tmp/finetuned_814_2347_model/config.json\") as f:\\n    config = json.load(f)\\nprint(config[\"num_labels\"])\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import json\n",
    "#with open(\"./tmp/finetuned_mod2347_model/config.json\") as f:\n",
    "with open(\"./tmp/finetuned_814_2347_model/config.json\") as f:\n",
    "    config = json.load(f)\n",
    "print(config[\"num_labels\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e56f1993-7761-4acd-a6e9-aca889eff488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DebertaV2ForSequenceClassification(\n",
       "      (deberta): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (pooler): ContextPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ft_lora_model\n",
    "loaded_peft_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c7fde-21de-484e-86a7-61fea432dbbd",
   "metadata": {},
   "source": [
    "### Function to perform evaluate model performance (same function will be used for before and after model fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54d2b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate both the initial performance of the pretrained model with the dataset \n",
    "# to then to use to evaluate the pretrained fine-tuned model with the dataset \n",
    "\n",
    "kpi = evaluate.load(\"accuracy\")\n",
    "\n",
    "def model_evaluating(model, dataset, batch_size=1):\n",
    "    model.eval()\n",
    "    model.to(\"cuda\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    for i in dataloader:\n",
    "        input_ids = i[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = i[\"attention_mask\"].to(\"cuda\")\n",
    "        labels = i[\"label\"].to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        kpi.add_batch(predictions=predictions, references=labels)\n",
    "    \n",
    "    return kpi.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a847c4d1-99d7-4b58-85fe-95507269ecb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 1. Load PEFT config to find base model name\\npeft_model_path = \"./tmp/original_lora_peft_8142133_model\"  \\npeft_config = PeftConfig.from_pretrained(peft_model_path)\\n\\n# 2. Load base model with correct label count\\nmy_model = DebertaV2ForSequenceClassification.from_pretrained(\\n    \\'microsoft/deberta-v3-small\\', \\n    num_labels=4,\\n    ignore_mismatched_sizes=True,\\n    use_safetensors=True \\n    )\\n\\n# 3. Load LoRA adapter on top of base model\\noriginal_lora_peft = PeftModel.from_pretrained(my_model, peft_model_path)\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practicing correct LoRA peft load\n",
    "'''\n",
    "# 1. Load PEFT config to find base model name\n",
    "peft_model_path = \"./tmp/original_lora_peft_8142133_model\"  \n",
    "peft_config = PeftConfig.from_pretrained(peft_model_path)\n",
    "\n",
    "# 2. Load base model with correct label count\n",
    "my_model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    'microsoft/deberta-v3-small', \n",
    "    num_labels=4,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    use_safetensors=True \n",
    "    )\n",
    "\n",
    "# 3. Load LoRA adapter on top of base model\n",
    "original_lora_peft = PeftModel.from_pretrained(my_model, peft_model_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b69c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3257\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1421\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 374\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Now select and load a dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#my_dataset = load_dataset(\"emotion\")\n",
    "my_dataset = load_dataset(\"tweet_eval\", \"emotion\")\n",
    "\n",
    "dataset_splits = ['train', 'validation', 'test']\n",
    "\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57a316cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 3257\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review overall train dataset\n",
    "\n",
    "my_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0d756d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1421\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review overall test dataset\n",
    "\n",
    "my_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19ead520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the first example from the train dataset\n",
    "\n",
    "my_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0f8fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse',\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the first example from the validation dataset\n",
    "\n",
    "my_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee067ba4-c708-4d0f-a53f-e811b27fb117",
   "metadata": {},
   "source": [
    "### Key observation on the new tokenizer saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dbb00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making the saved variable the uploaded tokenizer from saving point\n",
    "\n",
    "\n",
    "my_tokenizer = new_tokenizer\n",
    "\n",
    "\n",
    "\n",
    "#my_tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v2-xlarge')\n",
    "\n",
    "# save tokenizer alongside the model\n",
    "#my_tokenizer.save_pretrained(\"./tmp/finetuned_814_2347_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e701217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a9b34f335c4c56b57a816758f91edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3257 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a5ba72f966488a85d2fa4c2bc5fda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a8d300940b487980991dc6e5b26a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Improved tokenizer version\n",
    "\n",
    "my_tokenized_dataset = {}\n",
    "\n",
    "for split in dataset_splits:\n",
    "    my_tokenized_dataset[split] = my_dataset[split].map(\n",
    "        #lambda x: my_tokenizer(x[\"text\"], truncation=True, padding=\"max_length\"), \n",
    "        lambda x: my_tokenizer(x[\"text\"], truncation=True, padding=True, return_tensors=\"pt\"), \n",
    "        batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "print(my_tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b17e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5292b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e9b2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\", 'label': 2, 'input_ids': [1, 68, 43422, 41870, 13, 10, 184, 1574, 21, 10, 453, 17, 111, 252, 30, 25, 4, 15282, 15583, 4, 1539, 76839, 1539, 71038, 1539, 118308, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "caabe4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse', 'label': 3, 'input_ids': [1, 1539, 99185, 56743, 13, 340, 4, 8583, 2564, 96, 1539, 2539, 30606, 98, 1276, 5826, 513, 5, 3291, 11, 59, 49, 2271, 120, 4, 1962, 11, 1539, 63270, 169, 10087, 93, 54082, 22, 2416, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242356b",
   "metadata": {},
   "source": [
    "## Performing the baseline evaluation of the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195a81a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db51ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 1421\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "my_tokenized_dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "#my_tokenized_dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "#tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(my_tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bde5d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149ccb9bbed8453ca9dc933bd08a35ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1421 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making sure the testing dataset is ready for evaluation\n",
    "\n",
    "my_testing_tokenized_dataset = my_tokenized_dataset[\"test\"].map(batched=True)\n",
    "\n",
    "my_testing_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14f5860f-70c7-4623-b82b-0248158a5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cache before running to allow enough memory for it\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "548baa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Evaluation: {'accuracy': 0.39268121041520054}\n"
     ]
    }
   ],
   "source": [
    "# Test initial accuracy of the pretrained Model on the selected dataset\n",
    "\n",
    "model_retrieval_results = model_evaluating(loaded_peft_model, my_testing_tokenized_dataset)\n",
    "print(\"Base Model Evaluation:\", model_retrieval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1049bc1-7df1-46df-90f8-7e4ce06afbbe",
   "metadata": {},
   "source": [
    "### Worked like a charm!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb12efb-e6f6-47f1-89f4-2eff52915f6c",
   "metadata": {},
   "source": [
    "#### This confirms what I was expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03730892-a889-441f-864e-dfb8e6e234dc",
   "metadata": {},
   "source": [
    "- The end -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
