{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6280d99-4322-43be-b10a-6761e2e97a51",
   "metadata": {},
   "source": [
    "#### Student: Rodrigo Quezada Reyes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ad2f77-ef7c-496f-865e-3491222b02ed",
   "metadata": {},
   "source": [
    "#### The Udacity platform was having Connection Failed over and over again during training or evaluation so rather perform locally with my GPU and will submit as a zip file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5050f-c7f5-4896-8c5f-65b20e657af0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "Describing my choices for each of the following:\n",
    "\n",
    "* PEFT technique: Lora as I find it a great option for fine-tuning while freezing a lot of paremeters for computation effiency.\n",
    "* Model: deberta-v2-xlarge because it is a great model for text classification tasks and this is one of those.\n",
    "* Evaluation approach: Performing initial evaluation with the foundational model, then performing the same evaluation using the trained Peft Model. This will allow a fair comparison of the model as is compared to the model fine-tuned.\n",
    "* Fine-tuning dataset: Hugging Face tweet_eval dataset as it is an interesting collection of tweet-based benchmark tasks designed for evaluating text classification models on social media content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "* I am selecting to load as my chosen pre-trained foundational model, the deberta-v2-xlarge after assessing its capability for classification tasks.\n",
    "* I will evaluate its performance prior to fine-tuning and then after fine-tuning. \n",
    "* I will also include loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d21f21",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e94f0",
   "metadata": {},
   "source": [
    "#### Import all dependencies including the Hugging Face PEFT Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335bc74f-d9a3-45c6-9fe3-f81c7f80a1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccc73b0-8dc6-4733-9ab6-e319da8ea71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b96d81-b39e-4b37-a763-44a19db347b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2feb3a30-517b-4ca9-ae67-ba567608d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f7ed12f-b484-44d2-8205-aa6bd78b8c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu126\n",
      "12.6\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Importing the torch library\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "889ac152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the rest of the libraries\n",
    "\n",
    "from peft import LoraConfig\n",
    "from peft import TaskType\n",
    "from transformers import AutoModelForCausalLM,AutoModelForSequenceClassification\n",
    "from peft import get_peft_model\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "from transformers import pipeline, DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from transformers import DebertaV2ForSequenceClassification, DebertaV2Tokenizer\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "import sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87fa2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "12.6\n"
     ]
    }
   ],
   "source": [
    "# Verify if GPU is available\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c536757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting this up because my session expires as it times out while I am training the model at Udacity platform\n",
    "# now running locally so no longer needed\n",
    "\n",
    "#import time\n",
    "#import threading\n",
    "\n",
    "#def keep_alive():\n",
    " #   while True:\n",
    "  #      print(\"Keeping the session alive...\")\n",
    "   #     time.sleep(300)  # Sleep for 5 minutes\n",
    "\n",
    "# Start the keep-alive thread\n",
    "#keep_alive_thread = threading.Thread(target=keep_alive)\n",
    "#keep_alive_thread.daemon = True  # This allows the thread to exit when the main program does\n",
    "#keep_alive_thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c7fde-21de-484e-86a7-61fea432dbbd",
   "metadata": {},
   "source": [
    "### Function to perform evaluate model performance (same function will be used for before and after model fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54d2b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate both the initial performance of the pretrained model with the dataset \n",
    "# to then to use to evaluate the pretrained fine-tuned model with the dataset \n",
    "\n",
    "kpi = evaluate.load(\"accuracy\")\n",
    "\n",
    "def model_evaluating(model, dataset, batch_size=1):\n",
    "    model.eval()\n",
    "    model.to(\"cuda\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "    \n",
    "    for i in dataloader:\n",
    "        input_ids = i[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = i[\"attention_mask\"].to(\"cuda\")\n",
    "        labels = i[\"label\"].to(\"cuda\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "        \n",
    "        kpi.add_batch(predictions=predictions, references=labels)\n",
    "    \n",
    "    return kpi.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e0b5e",
   "metadata": {},
   "source": [
    "## Loading the selected pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a12c5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3cd8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Creating a model object from a Converting a Transformer Model by loading my chosen pre-trained Hugging Face model: gpt2\n",
    "\n",
    "# At my local machine this model worked great but switching to alternative per the platform options\n",
    "#my_model = AutoModelForSequenceClassification.from_pretrained(\n",
    " #   \"bert-base-uncased\",\n",
    "  #  num_labels=6)\n",
    "    \n",
    "#my_model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    " #   \"microsoft/deberta-v3-base\",\n",
    "  #  num_labels=6\n",
    "#)\n",
    "           \n",
    "my_model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    'microsoft/deberta-v3-small', \n",
    "    num_labels=4,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    use_safetensors=True \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "Creating a PEFT model from my loaded model, run a training loop, and saving the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5775fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a PEFT model from your loaded mode\n",
    "\n",
    "# Creating a PEFT configuration object from a Lora function\n",
    "\n",
    "my_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,  # For sequence classification\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "# Creating a trainable PEFT model object from a PEFT function\n",
    "\n",
    "lora_peft_model = get_peft_model(my_model, my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b005892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 150,532 || all params: 142,048,520 || trainable%: 0.1060\n"
     ]
    }
   ],
   "source": [
    "# Confirmation on Lora is working so only some parameters can be fine-tuned\n",
    "\n",
    "lora_peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4058002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DebertaV2ForSequenceClassification(\n",
       "      (deberta): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (pooler): ContextPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observing the model object\n",
    "\n",
    "lora_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c1259bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the original peft model\n",
    "\n",
    "lora_peft_model.save_pretrained(\"./tmp/original_lora_peft_8142133_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a847c4d1-99d7-4b58-85fe-95507269ecb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\dslab\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\safetensors\\torch.py:315: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  result[k] = f.get_tensor(k)\n"
     ]
    }
   ],
   "source": [
    "# Practicing correct LoRA peft load\n",
    "\n",
    "# 1. Load PEFT config to find base model name\n",
    "peft_model_path = \"./tmp/original_lora_peft_8142133_model\"  \n",
    "peft_config = PeftConfig.from_pretrained(peft_model_path)\n",
    "\n",
    "# 2. Load base model with correct label count\n",
    "my_model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    'microsoft/deberta-v3-small', \n",
    "    num_labels=4,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    use_safetensors=True \n",
    "    )\n",
    "\n",
    "# 3. Load LoRA adapter on top of base model\n",
    "original_lora_peft = PeftModel.from_pretrained(my_model, peft_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6803c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DebertaV2ForSequenceClassification(\n",
       "      (deberta): DebertaV2Model(\n",
       "        (embeddings): DebertaV2Embeddings(\n",
       "          (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): DebertaV2Encoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-5): 6 x DebertaV2Layer(\n",
       "              (attention): DebertaV2Attention(\n",
       "                (self): DisentangledSelfAttention(\n",
       "                  (query_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (pos_dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): DebertaV2SelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): DebertaV2Intermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): DebertaV2Output(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (rel_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (pooler): ContextPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=4, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observing the retrieved model object\n",
    "\n",
    "original_lora_peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54876f6",
   "metadata": {},
   "source": [
    "I am selecting the tweet_eval dataset which is a collection of tweet-based benchmark tasks designed for evaluating text classification models on social media content. It includes several sub-tasks such as emotion classification, hate speech detection, irony, stance detection, and more—each with its own labeled subset. Tweets are short, informal, and often noisy, making the dataset ideal for developing and testing models in real-world, low-resource language scenarios. The dataset is widely used for benchmarking due to its diversity and compact size, with some sub-tasks (like the \"emotion\" subset) containing fewer than 4,000 training examples—making it especially suitable for training with limited computing resource because using the dataset emotion the traning crashes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b69c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 3257\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1421\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 374\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Now select and load a dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "#my_dataset = load_dataset(\"emotion\")\n",
    "my_dataset = load_dataset(\"tweet_eval\", \"emotion\")\n",
    "\n",
    "dataset_splits = ['train', 'validation', 'test']\n",
    "\n",
    "print(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a316cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 3257\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review overall train dataset\n",
    "\n",
    "my_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d756d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1421\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review overall test dataset\n",
    "\n",
    "my_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19ead520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\",\n",
       " 'label': 2}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the first example from the train dataset\n",
    "\n",
    "my_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0f8fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse',\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the first example from the validation dataset\n",
    "\n",
    "my_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbb00f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading an appropriate selected tokenizer\n",
    "\n",
    "my_tokenizer = DebertaV2Tokenizer.from_pretrained('microsoft/deberta-v2-xlarge')\n",
    "\n",
    "#my_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e701217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "# Improved tokenizer version\n",
    "\n",
    "my_tokenized_dataset = {}\n",
    "\n",
    "for split in dataset_splits:\n",
    "    my_tokenized_dataset[split] = my_dataset[split].map(\n",
    "        #lambda x: my_tokenizer(x[\"text\"], truncation=True, padding=\"max_length\"), \n",
    "        lambda x: my_tokenizer(x[\"text\"], truncation=True, padding=True, return_tensors=\"pt\"), \n",
    "        batched=True\n",
    "    )\n",
    "\n",
    "# Inspect the available columns in the dataset\n",
    "print(my_tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12b17e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"test\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5292b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e9b2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\", 'label': 2, 'input_ids': [1, 68, 43422, 41870, 13, 10, 184, 1574, 21, 10, 453, 17, 111, 252, 30, 25, 4, 15282, 15583, 4, 1539, 76839, 1539, 71038, 1539, 118308, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caabe4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '#Deppression is real. Partners w/ #depressed people truly dont understand the depth in which they affect us. Add in #anxiety &amp;makes it worse', 'label': 3, 'input_ids': [1, 1539, 99185, 56743, 13, 340, 4, 8583, 2564, 96, 1539, 2539, 30606, 98, 1276, 5826, 513, 5, 3291, 11, 59, 49, 2271, 120, 4, 1962, 11, 1539, 63270, 169, 10087, 93, 54082, 22, 2416, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(my_tokenized_dataset[\"test\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4242356b",
   "metadata": {},
   "source": [
    "## Performing the baseline evaluation of the pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195a81a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db51ab47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 1421\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "my_tokenized_dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "#my_tokenized_dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "#tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(my_tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bde5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the testing dataset is ready for evaluation\n",
    "\n",
    "my_testing_tokenized_dataset = my_tokenized_dataset[\"test\"].map(batched=True)\n",
    "\n",
    "my_testing_tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14f5860f-70c7-4623-b82b-0248158a5ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cache before running to allow enough memory for it\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "548baa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Evaluation: {'accuracy': 0.26882477128782545}\n"
     ]
    }
   ],
   "source": [
    "# Test initial accuracy of the pretrained Model on the selected dataset\n",
    "\n",
    "baseline_results = model_evaluating(original_lora_peft, my_testing_tokenized_dataset)\n",
    "print(\"Base Model Evaluation:\", baseline_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e038e50",
   "metadata": {},
   "source": [
    "## Apply PEFT to fine-tune the model efficiency via training it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d49d63",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6970e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cache before training to allow enough memory for it\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dslab\\AppData\\Local\\Temp\\ipykernel_11788\\2755494013.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6514' max='6514' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6514/6514 10:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.327700</td>\n",
       "      <td>1.388205</td>\n",
       "      <td>0.392681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.300100</td>\n",
       "      <td>1.420024</td>\n",
       "      <td>0.392681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6514, training_loss=1.3221184489256332, metrics={'train_runtime': 617.5189, 'train_samples_per_second': 10.549, 'train_steps_per_second': 10.549, 'total_flos': 114033337882464.0, 'train_loss': 1.3221184489256332, 'epoch': 2.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Run a training loop\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=original_lora_peft,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./tmp/patent_class\",\n",
    "        # Set the learning rate\n",
    "        learning_rate=2e-5,\n",
    "        # Set the per device train batch size and eval batch size\n",
    "        per_device_train_batch_size=1,\n",
    "        per_device_eval_batch_size=1,\n",
    "        # Evaluate and save the model after each epoch\n",
    "        #evaluation_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        # Set the learning rate\n",
    "        num_train_epochs=2,\n",
    "        weight_decay=0.01,\n",
    "        load_best_model_at_end=True,\n",
    "    ),\n",
    "    train_dataset=my_tokenized_dataset[\"train\"],\n",
    "    eval_dataset=my_tokenized_dataset[\"test\"],\n",
    "        \n",
    "    tokenizer=my_tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=my_tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8a663",
   "metadata": {},
   "source": [
    "###  ⚠️ IMPORTANT ⚠️\n",
    "\n",
    "Due to workspace storage constraints, you should not store the model weights in the same directory but rather use `/tmp` to avoid workspace crashes which are irrecoverable.\n",
    "Ensure you save it in /tmp always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f170049b-12fa-4934-ba43-ef85e80131cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge LoRA weights with base model\n",
    "\n",
    "ft_model = original_lora_peft.merge_and_unload()\n",
    "ft_model.save_pretrained(\"./tmp/finetuned_814_2347_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6bc31",
   "metadata": {},
   "source": [
    "## Now evaluate the foundational model performance after the PEFT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d94ac72-46e6-45ba-a431-c90c94337ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cache before running to allow enough memory for it\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d9dc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post PEFT fine-tune Model Evaluation: {'accuracy': 0.39268121041520054}\n"
     ]
    }
   ],
   "source": [
    "# Using the same evaluation method, now for the fine-tuned/trained peft model\n",
    "\n",
    "new_results = model_evaluating(ft_model, my_testing_tokenized_dataset)\n",
    "print(\"Post PEFT fine-tune Model Evaluation:\", new_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960ce28",
   "metadata": {},
   "source": [
    "## Compare performance before and after fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984d518e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4153108-d25b-41e5-945d-db9ac995da08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete cache before running to allow enough memory for it\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model:  {'accuracy': 0.26882477128782545}\n",
      "Fine-tuned Model:  {'accuracy': 0.39268121041520054}\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Model: \", baseline_results)\n",
    "print(\"Fine-tuned Model: \", new_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20711072",
   "metadata": {},
   "source": [
    "-The End-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
